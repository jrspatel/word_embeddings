Text embeddings are essential for projects relying on textual context, as computers interpret data as numbers. This project explores converting textual information into machine-readable language using techniques like "TF-IDF," "One-Hot Encoding," "GloVe," and "BERT." Here, I implemented the "Word2Vec" model. 

EXAMPLE : 

SENTENCE = "This is word embeddings project".

    words -> {word, embeddings, project} 
    
    window size = 2  
    
    context_words = {word, embeddings}
    
    target_words = {project}

